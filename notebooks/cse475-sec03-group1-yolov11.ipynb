{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13559967,"sourceType":"datasetVersion","datasetId":8613178},{"sourceId":13594370,"sourceType":"datasetVersion","datasetId":8637703}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üë• Group Information\n\n1. **Mahmudur Rahman Mehraj** ‚Äî ID: 2022-3-60-182  \n2. **MD. Robiul Islam** ‚Äî ID: 2023-1-60-093  \n3. **Sunzid Ashraf Mahi** ‚Äî ID: 2023-1-60-148\n","metadata":{"execution":{"iopub.status.busy":"2025-11-03T12:00:59.478168Z","iopub.execute_input":"2025-11-03T12:00:59.478395Z","iopub.status.idle":"2025-11-03T12:00:59.598531Z","shell.execute_reply.started":"2025-11-03T12:00:59.478367Z","shell.execute_reply":"2025-11-03T12:00:59.597649Z"},"id":"zUU8S7Q2uHJ8"}},{"cell_type":"markdown","source":"# Clear Current Output Directory","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Copy Dataset to working Directory","metadata":{}},{"cell_type":"code","source":"input_data_path = '/kaggle/input/object-detection-mendeley-yolo-v11/Object Detection Dataset  Navigation Assistance for the Visually Impaired People using YOLOv11/'\ninput_data_path2 = '/kaggle/input/object-detection-ewu/'\n!cp -r \"{input_data_path2}\"* /kaggle/working/\n\ndata_path = '/kaggle/working'\n","metadata":{"trusted":true,"id":"8Pygy71NuHJ_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Installations\n!pip install ttach\n!pip install ultralytics --no-deps\n!git clone https://github.com/rigvedrs/YOLO-V12-CAM.git\n%cd /kaggle/working/YOLO-V12-CAM","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\nimport os\nimport cv2\nimport yaml\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom yolo_cam.eigen_cam import EigenCAM\nfrom yolo_cam.utils.image import show_cam_on_image, scale_cam_image\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# YAML data loading","metadata":{}},{"cell_type":"code","source":"yaml_path = data_path + '/data.yaml'\noutput_yaml_path = '/kaggle/working/data.yaml'\n\nwith open(yaml_path, 'r') as file:\n    data = yaml.safe_load(file)\n\ndata['train'] = data_path + '/train/images'\ndata['val'] = data_path + '/valid/images'\ndata['test'] = data_path + '/test/images'\n\nwith open(output_yaml_path, 'w') as file:\n    yaml.dump(data, file, default_flow_style=False)\n\nprint(\"Updated data.yaml:\")\nprint(yaml.dump(data, default_flow_style=False))","metadata":{"trusted":true,"id":"dJU5twTwuHJ_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inspect_label_format(split_name=\"train\", num_files=3):\n    \"\"\"Inspect the format of label files\"\"\"\n    base_path = Path(data_path)\n    labels_path = base_path / split_name / \"labels\"\n\n    print(f\"üîç Inspecting label format in '{split_name}' split:\\n\")\n\n    label_files = list(labels_path.glob(\"*.txt\"))[:num_files]\n\n    for label_file in label_files:\n        print(f\"üìÑ File: {label_file.name}\")\n        with open(label_file, 'r') as f:\n            lines = f.readlines()[:3]\n            for i, line in enumerate(lines, 1):\n                parts = line.strip().split()\n                print(f\"   Line {i}: {len(parts)} values -> {line.strip()}\")\n        print()\n\ninspect_label_format()","metadata":{"trusted":true,"id":"qinM2zojuHKA"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization of YOLO dataset with polygon segmentation masks","metadata":{}},{"cell_type":"code","source":"def visualize_yolo_polygon_split(split_name, num_images=3):\n\n    base_path = Path(data_path)\n    images_path = base_path / split_name / \"images\"\n    labels_path = base_path / split_name / \"labels\"\n\n    # Class names\n    class_names = ['Bin', 'Building Pillar', 'Bus', 'CNG', 'Car', 'Cycle',\n                   'Electric Pole', 'Food Van', 'Food cart', 'Footpath', 'Leguna',\n                   'Motorcycle', 'Obstacle', 'Parking Cone', 'Person', 'Pickup',\n                   'Rickshaw', 'Stairs', 'Tree', 'Truck', 'Van', 'Van gari']\n\n    print(f\"\\nüì∏ Showing {num_images} sample images from '{split_name}' split\\n\")\n\n    # Get image files\n    image_files = list(images_path.glob(\"*.jpg\")) + list(images_path.glob(\"*.png\"))\n    image_files = image_files[:num_images]\n\n    # Create subplots\n    fig, axes = plt.subplots(1, len(image_files), figsize=(6*len(image_files), 6))\n    if len(image_files) == 1:\n        axes = [axes]\n\n    for idx, img_file in enumerate(image_files):\n        # Read image\n        img = cv2.imread(str(img_file))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        h, w = img.shape[:2]\n\n        # Read corresponding label\n        label_file = labels_path / f\"{img_file.stem}.txt\"\n\n        if label_file.exists():\n            with open(label_file, 'r') as f:\n                lines = f.readlines()\n\n            for line in lines:\n                parts = list(map(float, line.strip().split()))\n\n                if len(parts) >= 3:  # At least class + 1 point (x,y)\n                    cls = int(parts[0])\n\n                    # Extract polygon coordinates (all values after class ID)\n                    coords = parts[1:]\n\n                    # Reshape into (N, 2) array of (x, y) points\n                    num_points = len(coords) // 2\n                    polygon_points = np.array(coords[:num_points * 2]).reshape(-1, 2)\n\n                    # Convert normalized coordinates to pixel coordinates\n                    polygon_points[:, 0] *= w\n                    polygon_points[:, 1] *= h\n                    polygon_points = polygon_points.astype(np.int32)\n\n                    # Generate random color for this object\n                    color = tuple(np.random.randint(100, 255, 3).tolist())\n\n                    # Draw filled polygon (semi-transparent)\n                    overlay = img.copy()\n                    cv2.fillPoly(overlay, [polygon_points], color)\n                    img = cv2.addWeighted(img, 0.7, overlay, 0.3, 0)\n\n                    # Draw polygon outline\n                    cv2.polylines(img, [polygon_points], True, color, 2)\n\n                    # Add label at the top-left of the polygon\n                    label = class_names[cls] if cls < len(class_names) else f\"Class {cls}\"\n                    min_point = polygon_points.min(axis=0)\n                    cv2.putText(img, label, tuple(min_point),\n                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n\n        # Display\n        axes[idx].imshow(img)\n        axes[idx].axis('off')\n        axes[idx].set_title(f\"{img_file.name}\\n({w}x{h})\")\n\n    plt.tight_layout()\n    plt.show()\n\n# Visualize each split\nprint(\"=\" * 60)\nprint(\"TRAIN SPLIT\")\nprint(\"=\" * 60)\nvisualize_yolo_polygon_split(\"train\", num_images=3)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"VALIDATION SPLIT\")\nprint(\"=\" * 60)\nvisualize_yolo_polygon_split(\"valid\", num_images=3)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TEST SPLIT\")\nprint(\"=\" * 60)\nvisualize_yolo_polygon_split(\"test\", num_images=3)","metadata":{"trusted":true,"id":"pVSdKwHUuHKB"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Dataset YAML","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------\n# Load Dataset YAML\n# ------------------------------------------------------------\nyaml_path = Path(data_path + '/data.yaml')\n\nwith open(yaml_path, \"r\") as f:\n    data_cfg = yaml.safe_load(f)\n\nprint(\"‚úÖ Dataset loaded successfully:\")\nprint(yaml.dump(data_cfg, sort_keys=False))\n","metadata":{"trusted":true,"id":"ndNSm8XluHKC"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------------------------------------------\n# Hyper Parameters\n# ------------------------------------------------------------\nepoch = 50\nbatch_size = 64\nimage_size = 640\nlearning_rate = 0.01\nlearning_rate_fine = 0.001\npatience = 15\noptimizer = 'AdamW'\nIOU = 0.7","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# YOLO v11\n## Model Training","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------\n# Training\n# ------------------------------------------------------------\nmodel = YOLO(\"yolo11n.pt\")\n\nresults = model.train(\n    data=str(yaml_path),\n    epochs=epoch,              # ‚Üê More epochs for 22 classes\n    patience=patience,             # ‚Üê Longer patience for complex task\n    imgsz=image_size,               # Or 800 if GPU memory allows\n    batch=batch_size,                # ‚Üê Reduced batch for better gradient updates\n    project=\"/kaggle/working\",\n    name=\"yolov11\",\n    device=0,\n    workers=2,\n    exist_ok=True,\n    \n    # Learning rate - important for multi-class\n    lr0=learning_rate,\n    lrf=learning_rate_fine,               # ‚Üê Lower final LR for fine-tuning\n\n    \n    # Stronger augmentation for 22 classes\n    hsv_h=0.015,             # HSV-Hue augmentation\n    hsv_s=0.7,               # HSV-Saturation\n    hsv_v=0.4,               # HSV-Value\n    degrees=20.0,            # Rotation\n    translate=0.2,           # Translation\n    scale=0.7,               # Scale\n    shear=2.0,               # Shear\n    perspective=0.0001,      # Perspective\n    flipud=0.0,              # No vertical flip\n    fliplr=0.5,              # Horizontal flip\n    mosaic=1.0,              # Mosaic (great for multi-class)\n    mixup=0.2,               # Mixup\n    copy_paste=0.5,          # ‚Üê Higher for rare classes\n    \n    # Multi-class optimization\n    optimizer=optimizer,\n    weight_decay=0.0005,\n    momentum=0.937,\n    close_mosaic=10,         # Disable mosaic in last 10 epochs\n    \n    # Class-specific settings\n    cls=0.5,                 # ‚Üê Class loss weight (important!)\n    box=7.5,                 # Box loss weight\n    dfl=1.5,                 # DFL loss weight\n    \n    # NMS settings for multiple classes\n    iou=IOU,                 # IoU threshold\n    conf=0.001,              # Low conf during training\n    \n    # Validation\n    val=True,\n    save=True,\n    save_period=25,\n    plots=True,\n    \n    # Performance\n    amp=True,\n    rect=False,              # Rectangular training (can help)\n    \n    # Verbose\n    verbose=True,\n)\n\nprint(\"\\n‚úÖ Training complete. Best model saved in:\")\nprint(model.ckpt_path)","metadata":{"trusted":true,"id":"9QrekpsCuHKC"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation on Validation and Test Sets","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------\n# Evaluation on Validation and Test Sets\n# ------------------------------------------------------------\nprint(\"\\nüìä Evaluating on validation set...\")\nval_metrics = model.val(data=str(yaml_path), split=\"val\")\nprint(\"\\nValidation Results:\")\n# print(val_metrics)\n\nprint(\"\\nüìä Evaluating on test set...\")\ntest_metrics = model.val(data=str(yaml_path), split=\"test\")\nprint(\"\\nTest Results:\")\n# print(test_metrics)","metadata":{"trusted":true,"id":"BlQmavfDuHKD"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Predictions Visualization","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------\n# Training Predictions Visualization\n# ------------------------------------------------------------\nprint(\"\\nüß† Running inference for visualization...\")\n\nval_path = Path((data_cfg[\"val\"])[0:])\nprint(f\"Looking for images in: {val_path}\")\n\nsample_imgs = list(val_path.glob(\"*.jpg\")) + list(val_path.glob(\"*.png\"))\n\nif not sample_imgs:\n    print(f\"‚ùå No images found in {val_path}\")\n    print(\"Available files:\")\n    print(list(val_path.glob(\"*\"))[:10])\nelse:\n    print(f\"‚úÖ Found {len(sample_imgs)} images\")\n\n    num_samples = min(10, len(sample_imgs))\n    sample_imgs = random.sample(sample_imgs, num_samples)\n\n    for img_path in sample_imgs:\n        print(f\"\\nüì∏ Processing: {img_path.name}\")\n\n        results = model(str(img_path))\n        annotated = results[0].plot() \n\n        plt.figure(figsize=(10, 10))\n        plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n        plt.axis(\"off\")\n        plt.title(f\"Predicted: {img_path.name}\", fontsize=14, fontweight='bold')\n        plt.tight_layout()\n        plt.show()\n\n        boxes = results[0].boxes\n        if len(boxes) > 0:\n            print(f\"   Detected {len(boxes)} objects\")\n            for box in boxes:\n                cls_id = int(box.cls[0])\n                conf = float(box.conf[0])\n                cls_name = model.names[cls_id]\n                print(f\"   - {cls_name}: {conf:.2%}\")\n        else:\n            print(\"   No objects detected\")","metadata":{"trusted":true,"id":"I1cOVVdYuHKD"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss and mAP Curves ","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------\n# Loss and mAP Curves \n# ------------------------------------------------------------\nresults_csv = '/kaggle/working/yolov11/results.csv'\n\nif not os.path.exists(results_csv):\n    print(f\"‚ùå results.csv not found at {results_csv}\")\nelse:\n    # Load metrics\n    df = pd.read_csv(results_csv)\n    print(f\"\\n‚úÖ Loaded training metrics from: {results_csv}\")\n    print(f\"Available columns: {df.columns.tolist()}\")\n    \n    # Clean column names (remove leading/trailing spaces)\n    df.columns = df.columns.str.strip()\n    \n    # Create output directory\n    output_dir = '/kaggle/working/yolov11/training_plots'\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # ------------------------------------------------------------\n    # Plot 1: Loss curves\n    # ------------------------------------------------------------\n    plt.figure(figsize=(12, 6))\n    plt.plot(df.index, df[\"train/box_loss\"], label=\"Box Loss\", color=\"red\", linewidth=2)\n    plt.plot(df.index, df[\"train/cls_loss\"], label=\"Class Loss\", color=\"blue\", linewidth=2)\n    plt.plot(df.index, df[\"train/dfl_loss\"], label=\"DFL Loss\", color=\"green\", linewidth=2)\n    plt.xlabel(\"Epoch\", fontsize=12)\n    plt.ylabel(\"Loss\", fontsize=12)\n    plt.title(\"YOLOv11 Training Loss Curves\", fontsize=14, fontweight='bold')\n    plt.legend(fontsize=11)\n    plt.grid(True, linestyle=\"--\", alpha=0.5)\n    plt.tight_layout()\n    \n    # Save to working directory (shows up in Kaggle output)\n    loss_plot_path = os.path.join(output_dir, 'training_loss_curves.png')\n    plt.savefig(loss_plot_path, dpi=150, bbox_inches='tight')\n    print(f\"‚úÖ Saved loss plot to: {loss_plot_path}\")\n    plt.show()\n    plt.close()\n    \n    # ------------------------------------------------------------\n    # Plot 2: mAP curves\n    # ------------------------------------------------------------\n    plt.figure(figsize=(12, 6))\n    plt.plot(df.index, df[\"metrics/mAP50(B)\"], label=\"mAP@0.5\", \n             color=\"orange\", linewidth=2, marker='o', markersize=3)\n    plt.plot(df.index, df[\"metrics/mAP50-95(B)\"], label=\"mAP@0.5:0.95\", \n             color=\"purple\", linewidth=2, marker='s', markersize=3)\n    plt.xlabel(\"Epoch\", fontsize=12)\n    plt.ylabel(\"mAP\", fontsize=12)\n    plt.title(\"YOLOv11 Validation mAP Curves\", fontsize=14, fontweight='bold')\n    plt.legend(fontsize=11)\n    plt.grid(True, linestyle=\"--\", alpha=0.5)\n    plt.tight_layout()\n    \n    # Save to working directory\n    map_plot_path = os.path.join(output_dir, 'validation_mAP_curves.png')\n    plt.savefig(map_plot_path, dpi=150, bbox_inches='tight')\n    print(f\"‚úÖ Saved mAP plot to: {map_plot_path}\")\n    plt.show()\n    plt.close()\n    \n    # ------------------------------------------------------------\n    # Plot 3: Combined metrics (Precision, Recall, mAP)\n    # ------------------------------------------------------------\n    plt.figure(figsize=(12, 6))\n    plt.plot(df.index, df[\"metrics/precision(B)\"], label=\"Precision\", \n             color=\"green\", linewidth=2, marker='^', markersize=3)\n    plt.plot(df.index, df[\"metrics/recall(B)\"], label=\"Recall\", \n             color=\"red\", linewidth=2, marker='v', markersize=3)\n    plt.plot(df.index, df[\"metrics/mAP50(B)\"], label=\"mAP@0.5\", \n             color=\"blue\", linewidth=2, marker='o', markersize=3)\n    plt.xlabel(\"Epoch\", fontsize=12)\n    plt.ylabel(\"Score\", fontsize=12)\n    plt.title(\"YOLOv11 Validation Metrics\", fontsize=14, fontweight='bold')\n    plt.legend(fontsize=11)\n    plt.grid(True, linestyle=\"--\", alpha=0.5)\n    plt.ylim([0, 1])  # Set y-axis from 0 to 1\n    plt.tight_layout()\n    \n    # Save to working directory\n    metrics_plot_path = os.path.join(output_dir, 'validation_metrics.png')\n    plt.savefig(metrics_plot_path, dpi=150, bbox_inches='tight')\n    print(f\"‚úÖ Saved metrics plot to: {metrics_plot_path}\")\n    plt.show()\n    plt.close()\n    \n    # ------------------------------------------------------------\n    # Plot 4: All losses in one subplot\n    # ------------------------------------------------------------\n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    \n    # Training losses\n    axes[0, 0].plot(df.index, df[\"train/box_loss\"], color=\"red\", linewidth=2)\n    axes[0, 0].set_title(\"Box Loss\", fontweight='bold')\n    axes[0, 0].set_xlabel(\"Epoch\")\n    axes[0, 0].grid(True, alpha=0.3)\n    \n    axes[0, 1].plot(df.index, df[\"train/cls_loss\"], color=\"blue\", linewidth=2)\n    axes[0, 1].set_title(\"Class Loss\", fontweight='bold')\n    axes[0, 1].set_xlabel(\"Epoch\")\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    axes[1, 0].plot(df.index, df[\"train/dfl_loss\"], color=\"green\", linewidth=2)\n    axes[1, 0].set_title(\"DFL Loss\", fontweight='bold')\n    axes[1, 0].set_xlabel(\"Epoch\")\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    # mAP comparison\n    axes[1, 1].plot(df.index, df[\"metrics/mAP50(B)\"], label=\"mAP@0.5\", \n                    color=\"orange\", linewidth=2)\n    axes[1, 1].plot(df.index, df[\"metrics/mAP50-95(B)\"], label=\"mAP@0.5:0.95\", \n                    color=\"purple\", linewidth=2)\n    axes[1, 1].set_title(\"mAP Scores\", fontweight='bold')\n    axes[1, 1].set_xlabel(\"Epoch\")\n    axes[1, 1].legend()\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    \n    # Save combined plot\n    combined_plot_path = os.path.join(output_dir, 'training_summary.png')\n    plt.savefig(combined_plot_path, dpi=150, bbox_inches='tight')\n    print(f\"‚úÖ Saved combined plot to: {combined_plot_path}\")\n    plt.show()\n    plt.close()\n    \n    # ------------------------------------------------------------\n    # Save summary statistics\n    # ------------------------------------------------------------\n    summary_path = os.path.join(output_dir, 'training_summary.txt')\n    with open(summary_path, 'w') as f:\n        f.write(\"YOLOv11 Training Summary\\n\")\n        f.write(\"=\" * 60 + \"\\n\\n\")\n        f.write(f\"Total Epochs: {len(df)}\\n\\n\")\n        \n        f.write(\"Final Metrics:\\n\")\n        f.write(\"-\" * 60 + \"\\n\")\n        f.write(f\"Train Box Loss: {df['train/box_loss'].iloc[-1]:.4f}\\n\")\n        f.write(f\"Train Class Loss: {df['train/cls_loss'].iloc[-1]:.4f}\\n\")\n        f.write(f\"Train DFL Loss: {df['train/dfl_loss'].iloc[-1]:.4f}\\n\\n\")\n        \n        f.write(f\"Validation Precision: {df['metrics/precision(B)'].iloc[-1]:.4f}\\n\")\n        f.write(f\"Validation Recall: {df['metrics/recall(B)'].iloc[-1]:.4f}\\n\")\n        f.write(f\"Validation mAP@0.5: {df['metrics/mAP50(B)'].iloc[-1]:.4f}\\n\")\n        f.write(f\"Validation mAP@0.5:0.95: {df['metrics/mAP50-95(B)'].iloc[-1]:.4f}\\n\\n\")\n        \n        f.write(\"Best Metrics:\\n\")\n        f.write(\"-\" * 60 + \"\\n\")\n        f.write(f\"Best mAP@0.5: {df['metrics/mAP50(B)'].max():.4f} at epoch {df['metrics/mAP50(B)'].idxmax()}\\n\")\n        f.write(f\"Best mAP@0.5:0.95: {df['metrics/mAP50-95(B)'].max():.4f} at epoch {df['metrics/mAP50-95(B)'].idxmax()}\\n\")\n        f.write(f\"Best Precision: {df['metrics/precision(B)'].max():.4f} at epoch {df['metrics/precision(B)'].idxmax()}\\n\")\n        f.write(f\"Best Recall: {df['metrics/recall(B)'].max():.4f} at epoch {df['metrics/recall(B)'].idxmax()}\\n\")\n    \n    print(f\"‚úÖ Saved training summary to: {summary_path}\")\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"üìÅ All plots and summary saved to: {output_dir}\")\n    print(f\"{'='*60}\")\n    print(f\"\\nFiles created:\")\n    print(f\"  1. training_loss_curves.png\")\n    print(f\"  2. validation_mAP_curves.png\")\n    print(f\"  3. validation_metrics.png\")\n    print(f\"  4. training_summary.png\")\n    print(f\"  5. training_summary.txt\")\n","metadata":{"trusted":true,"id":"AaQ3lz0uuHKD"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## XAI\n","metadata":{"id":"6n_iJ6OcuHKE"}},{"cell_type":"code","source":"%cd /kaggle/working/YOLO-V12-CAM","metadata":{"trusted":true,"id":"-N_LPTlBuHKE"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(data_path + '/yolov11/weights/best.pt')\nmodel = model.cpu()","metadata":{"trusted":true,"id":"O6f5IGVruHKF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv2.imread('/kaggle/input/object-detection-ewu/train/images/frame_0s_jpg.rf.05d81773433c10ba035e8c1c7a6e8407.jpg')\nimg = cv2.resize(img, (640, 640))\nrgb_img = img.copy()\nimg = np.float32(img) / 255","metadata":{"trusted":true,"id":"NvCkuXS_uHKF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_layers =[model.model.model[-2]]","metadata":{"trusted":true,"id":"q5ZfuM3xuHKF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cam = EigenCAM(model, target_layers,task='od')\ngrayscale_cam = cam(rgb_img)[0, :, :]\ncam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\nplt.imshow(cam_image)\nplt.show()","metadata":{"trusted":true,"id":"EYCXn5iSuHKF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"g_scale = np.stack([grayscale_cam] * 3, axis=2)\nplt.imshow(g_scale)","metadata":{"trusted":true,"id":"segyw8WEuHKF"},"outputs":[],"execution_count":null}]}